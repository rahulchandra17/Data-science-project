{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('breast_cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mean radius  mean texture  mean perimeter  mean area  \\\n",
       "0           0        17.99         10.38          122.80     1001.0   \n",
       "1           1        20.57         17.77          132.90     1326.0   \n",
       "2           2        19.69         21.25          130.00     1203.0   \n",
       "3           3        11.42         20.38           77.58      386.1   \n",
       "4           4        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   mean symmetry  ...  worst perimeter  worst area  worst smoothness  \\\n",
       "0         0.2419  ...           184.60      2019.0            0.1622   \n",
       "1         0.1812  ...           158.80      1956.0            0.1238   \n",
       "2         0.2069  ...           152.50      1709.0            0.1444   \n",
       "3         0.2597  ...            98.87       567.7            0.2098   \n",
       "4         0.1809  ...           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  target  target_names  \n",
       "0                  0.11890       0     malignant  \n",
       "1                  0.08902       0     malignant  \n",
       "2                  0.08758       0     malignant  \n",
       "3                  0.17300       0     malignant  \n",
       "4                  0.07678       0     malignant  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(['Unnamed: 0','target_names'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malignant 212\n",
      "benign 357\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEJCAYAAAB/pOvWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAXSklEQVR4nO3dfZRddX3v8fcMSSAliYQwGh7kQTFfRRGQJFZ5igoqra1yMVWD0lQepIqXdRUpXuOVUFuU3hUoFMstEKBGEAFRIcS6mqBcHkRFkGrge7E3UDDTSxytTaIhCTP3j71ncZI9MzkzmT1nZvJ+rcXinH1+e+/vsDbns3+/ffZvt/X09CBJUqP2VhcgSRp9DAdJUoXhIEmqMBwkSRWGgySpYkKrCxgGuwNzgE7ghRbXIkljxW7AvsAPgee3/3A8hMMc4H+3ughJGqOOA+7bfuF4CIdOgF//eiPd3d6zIUnNaG9vY/r0PaH8Dt3eeAiHFwC6u3sMB0kavD6H470gLUmqMBwkSRWGgySpwnCQJFUYDpKkCsNBklRhOEiSKsbDfQ7SuDb9JZOYMGn3VpehUWbr5uf59W8217b9WsMhIi4G3gv0ANdl5pKIuB44FthYNlucmXdExInAEmAycEtmLqqzNmmsmDBpdx6+9MxWl6FR5ugLrgXGYDhExAnAW4HXAxOB1RGxHJgNHJ+ZnQ1tJwNLgROAZ4DlEXFyZq6oqz5JUv9qu+aQmd8D3pKZW4GXUgTR74ADgaUR8VhELI6IdmAu8GRmrinbLwPm11WbJGlgtQ4rZeaWiFgMnA/cStGDWAV8FPgNcBdwBrCBbSd/6gQOGMy+ZsyYMhwlS9KY0dExtbZt135BOjM/FxFfBO4E3paZp/R+FhFXAqcDt1Fcl+jVBnQPZj9dXRuceE/jUp1fABrb1q1bP+R129vbBjyprm1YKSJeHRFHAmTmb4GvA++LiFMbmrUBW4BnKR460WsmsLau2iRJA6uz5/AKYHFEHEvRK3g38D3g8ohYRTGUdDZwI/AQEBFxKLAGWEBxgVqS1AJ1XpC+G1gOPAI8DDyQmRcDlwD3A6uBRzPz5szcBCwEbi+XP0Ex1CRJaoG2np4xP05/MLDGaw4arzo6pnqfgyqOvuDa4brmcAjwVOXzIW9ZkjRuGQ6SpArDQZJUYThIkioMB0lSheEgSaowHCRJFYaDJKnCcJAkVRgOkqQKw0GSVGE4SJIqDAdJUoXhIEmqMBwkSRWGgySpwnCQJFUYDpKkCsNBklRhOEiSKibUufGIuBh4L9ADXJeZSyLiRGAJMBm4JTMXlW2PBK4FpgH3Audk5tY665Mk9a22nkNEnAC8FXg9MBv4eEQcASwF3g28BpgTESeXqywDzs3MWUAbcFZdtUmSBlZbOGTm94C3lGf/L6XopewFPJmZa8rly4D5EXEQMDkzv1+ufgMwv67aJEkDq3VYKTO3RMRi4HzgVmA/oLOhSSdwwADLmzZjxpSdK1aSxpiOjqm1bbvWcADIzM9FxBeBO4FZFNcferUB3RQ9mL6WN62rawPd3T07biiNMXV+AWhsW7du/ZDXbW9vG/Ckus5rDq8uLzKTmb8Fvg7MA/ZtaDYTWAs8289ySVIL1PlT1lcA10TE7hExieIi9P8CIiIOjYjdgAXAisx8GtgUEceU634IWFFjbZKkAdR5QfpuYDnwCPAw8EBmfhVYCNwOrAaeAG4rVzkNuCwingCmAFfUVZskaWB1X5C+CLhou2UrgSP6aPsTYG6d9UiSmuMd0pKkCsNBklRhOEiSKgwHSVKF4SBJqjAcJEkVhoMkqcJwkCRVGA6SpArDQZJUYThIkioMB0lSheEgSaowHCRJFYaDJKnCcJAkVRgOkqQKw0GSVGE4SJIqDAdJUsWEOjceEZ8D/qR8uzwzL4iI64FjgY3l8sWZeUdEnAgsASYDt2TmojprkyT1r7ZwKL/s3w4cBfQA346IU4DZwPGZ2dnQdjKwFDgBeAZYHhEnZ+aKuuqTJPWvzp5DJ/DJzNwMEBGPAweW/yyNiP2BO4DFwFzgycxcU7ZdBswHDAdJaoHawiEzf9b7OiJeRTG8dBwwD/go8BvgLuAMYANFmPTqBA4YzP5mzJiycwVL0hjT0TG1tm3Xes0BICJeCywHPpWZCZzS8NmVwOnAbRRDT73agO7B7KerawPd3T07biiNMXV+AWhsW7du/ZDXbW9vG/CkutZfK0XEMcBK4MLMvDEiDo+IUxuatAFbgGeBfRuWzwTW1lmbJKl/dV6QfjnwDeB9mbmqXNwGXB4RqyiGks4GbgQeKlaJQ4E1wAKKC9SSpBaoc1jpfGAPYElE9C67GrgEuB+YCNyemTcDRMRC4PZynbsphpokSS1Q5wXp84Dz+vn4S320XwkcUVc9kqTmeYe0JKnCcJAkVRgOkqQKw0GSVGE4SJIqDAdJUoXhIEmqMBwkSRWGgySpwnCQJFUYDpKkCsNBklRhOEiSKgwHSVKF4SBJqjAcJEkVdT4JbkyZOm0P9th9YqvL0Ciz6fktrP/PTa0uQxpxhkNpj90nsuCCr7S6DI0yN116GusxHLTraWpYKSL272PZYcNfjiRpNBiw5xARe5cv746IeUBb+X4i8HXg1fWVJklqlR0NK90MnFS+7mpYvhW4bUcbj4jPAX9Svl2emRdExInAEmAycEtmLirbHglcC0wD7gXOycytzf4hkqThM+CwUma+IzPbgRsys73hn0mZuWCgdcsQeDtwFHAkcHREfABYCrwbeA0wJyJOLldZBpybmbMoeihn7dRfJkkasqYuSGfmhyPiIGBvXhxaIjN/PMBqncAnM3MzQEQ8DswCnszMNeWyZcD8iFgNTM7M75fr3gAsBv5+cH+OJGk4NBUOEbEY+BTwHNBTLu4BXtHfOpn5s4b1X0UxvHQlRWj06gQOAPbrZ3nTZsyYMpjmUtM6Oqa2ugSpT3Uem83+lPV04NDMXDvYHUTEa4HlFOGylaL30KsN6KYY3urpY3nTuro20N3ds+OG/fALQP1Zt259S/fvsan+7Myx2d7eNuBJdbN3SD8zxGA4BlgJXJiZNwLPAvs2NJkJrB1guSSpBZrtOayMiEuBbwK/61040DWHiHg58A3gfZm5qlz8UPFRHAqsARYASzPz6YjYFBHHZOb9wIeAFYP/cyRJw6HZcFhY/nt+w7IBrzkA5wN7AEsionfZ1eW2bi8/u5sXfxJ7GnBNREwDfgxc0WRtkqRh1uyvlQ4Z7IYz8zzgvH4+PqKP9j8B5g52P5Kk4dfsr5U+0dfyzFwyvOVIkkaDZoeVDm94PQk4geJCsyRpHGp2WOnPGt9HxH7AdbVUJElquSE97Kf8WevBw1uKJGm0GMo1hzZgNsXd0pKkcWgo1xx6gH+juONZkjQODeqaQzn53sTM/HmtVUmSWqrZYaVDKe6O3g9oj4hfAu/KzMfrLE6S1BrNXpD+O+DSzJyemS8BPg9cVV9ZkqRWajYcXlZOnAdAZl4PdNRTkiSp1ZoNhwkNz5MmIvZh2ym2JUnjSLO/VroS+H5E3EIRCu8HLqutKklSSzXbc7ibIhQmAYcB+wN31FWUJKm1mg2HG4CrMvMvgA8CnwGW1lWUJKm1mg2HfTLzCoDM3JSZl7Ptk9skSePIYC5I79f7JiJeRjGNhiRpHGr2gvQS4NGI+DbFtYcTcfoMSRq3muo5ZOZSikB4BPgR8I7MvKnOwiRJrdNsz4HMfAx4rMZaJEmjxJCe5yBJGt+a7jkMVURMAx6gmKjvqYi4HjgW2Fg2WZyZd0TEiRTXNiYDt2TmorprkyT1rdZwiIg3AtcAsxoWzwaOz8zOhnaTKe6bOAF4BlgeESdn5oo665Mk9a3unsNZwMeALwNExO8BBwJLI6L3LuvFwFzgycxcU7ZbBswHDAdJaoFawyEzzwSIiN5FM4FVwEeB3wB3AWcAG4DOhlU7gQMGs68ZM6bsZLVS3zo6pra6BKlPdR6btV9zaJSZ/xc4pfd9RFwJnA7cxrazvLYB3YPZdlfXBrq7hz5RrF8A6s+6detbun+PTfVnZ47N9va2AU+qR/TXShFxeESc2rCoDdgCPMu203HMBNaOZG2SpBeNaM+BIgwuj4hVFENJZwM3Ag8BUT6OdA2wACf2k6SWGdGeQ3kj3SXA/cBq4NHMvDkzNwELgdvL5U9QDDVJklpgRHoOmXlww+svAV/qo81K4IiRqEeSNDDvkJYkVRgOkqQKw0GSVGE4SJIqDAdJUoXhIEmqMBwkSRWGgySpwnCQJFUYDpKkCsNBklRhOEiSKgwHSVKF4SBJqjAcJEkVhoMkqcJwkCRVGA6SpArDQZJUYThIkiom1LnxiJgGPAC8KzOfiogTgSXAZOCWzFxUtjsSuBaYBtwLnJOZW+usTZLUv9p6DhHxRuA+YFb5fjKwFHg38BpgTkScXDZfBpybmbOANuCsuuqSJO1YncNKZwEfA9aW7+cCT2bmmrJXsAyYHxEHAZMz8/tluxuA+TXWJUnagdqGlTLzTICI6F20H9DZ0KQTOGCA5YMyY8aUIdUp7UhHx9RWlyD1qc5js9ZrDttpB3oa3rcB3QMsH5Surg10d/fsuGE//AJQf9atW9/S/Xtsqj87c2y2t7cNeFI9kr9WehbYt+H9TIohp/6WS5JaZCTD4SEgIuLQiNgNWACsyMyngU0RcUzZ7kPAihGsS5K0nRELh8zcBCwEbgdWA08At5UfnwZcFhFPAFOAK0aqLklSVe3XHDLz4IbXK4Ej+mjzE4pfM0mSRgHvkJYkVRgOkqQKw0GSVGE4SJIqDAdJUoXhIEmqMBwkSRWGgySpwnCQJFUYDpKkCsNBklRhOEiSKgwHSVKF4SBJqjAcJEkVhoMkqcJwkCRVGA6SpArDQZJUYThIkiomtGKnEXEP8FJgS7noI8ArgUXARODyzLyqFbVJkloQDhHRBswCDsrMreWy/YGvAkcDzwMPRMQ9mbl6pOuTJLWm5xDlv78TETOAa4D1wKrM/BVARNwGvBe4uAX1SdIurxXhMB1YCXycYgjpu8AtQGdDm05g7mA2OmPGlGEqT9pWR8fUVpcg9anOY3PEwyEzHwQe7H0fEdcBS4DPNzRrA7oHs92urg10d/cMuS6/ANSfdevWt3T/Hpvqz84cm+3tbQOeVI/4r5Ui4tiIeFvDojbgKWDfhmUzgbUjWZck6UWtGFbaC7g4It5MMaz0p8AHgWUR0QFsBE4Fzm5BbZIkWtBzyMy7gOXAI8DDwNLMvB/4DHAP8ChwU2b+YKRrkyQVWnKfQ2Z+FvjsdstuAm5qRT2SpG15h7QkqcJwkCRVGA6SpArDQZJUYThIkioMB0lSheEgSaowHCRJFYaDJKnCcJAkVRgOkqQKw0GSVGE4SJIqDAdJUoXhIEmqMBwkSRWGgySpwnCQJFUYDpKkCsNBklQxodUFNIqIBcAiYCJweWZe1eKSJGmXNGp6DhGxP/BXwLHAkcDZEXFYa6uSpF3TaOo5nAisysxfAUTEbcB7gYt3sN5uAO3tbTtdwD7T99zpbWj8GY5ja2dNmjaj1SVoFNqZY7Nh3d36+nw0hcN+QGfD+05gbhPr7QswfRi+2K/49Ht2ehsaf2bMmNLqEjj8nC+2ugSNQsN0bO4L/Ov2C0dTOLQDPQ3v24DuJtb7IXAcRZi8UENdkjQe7UYRDD/s68PRFA7PUnzJ95oJrG1iveeB+2qpSJLGt0qPoddoCod/Bi6KiA5gI3AqcHZrS5KkXdOo+bVSZv4C+AxwD/AocFNm/qC1VUnSrqmtp6dnx60kSbuUUdNzkCSNHoaDJKnCcJAkVRgOkqQKw2EXFBFPRcTBEfHHEbGj6UmGa5+HRMR1I7EvjV4RMS8ivjsM27k2ImYPQ0nqx2i6z0EjLDO/BXxrhHZ3EPDKEdqXxrnMPLPVNYx3hsMYFRHzKO4L2QwcQvElvwF4D8XUI38AzAc+BOxZtvtAZmbDNhYC8zJzYbm9K4GtwIPAYZnZe5b3A4q71zuAj2fmioh4Xdl+CvBS4JLMvDoiLgL2B15FEQjXZuZfAVcAr4iIqzLzYzX9Z9HYsE9EfJviOHkI+BjwFopJNicCa4CzMrMrIp4Cvgy8g+I4Pj0zHy6Py4sy87sRcQnFJJ2/pJhG51vAd4E7gJ8CRwH/D5jfO7GndsxhpbHtjcA5wGzgXGBdZs4GHgPeTxEU8zLzdcBdZZuKiJhI8T/gaZl5FLBluyaTMvNNwH8DPl8uOxP4fGbOofgf+28a2r8eeHtZ34URsRfwX4EfGQyiOJn5OMVxMhW4EPgC8I7y+PsnoHGmwa7MnAtcDfz3xg1FxB9RTPP/WooToqMaPj4CWFIe//8BnFbLXzNO2XMY236amc8ARMQvgZXl8qeB6cAC4P0RMQt4J8Wd5305HHguMx8r3y8F/rbh82/37g/Yu3z9SeCdEfHpcv3G6SHvyczNwHMR8SvgJUP8+zQ+3ZuZTwJExFeAGykm3bwnIqCYEK7xDL/x+Psv223rJOBr5fG2OSK+0fDZc5n5SMO6e6OmGQ5j2+bt3m9teP1yiuGhvwNWAP/OtmdVjV5g4F7kpvLfPRRDVgBfA34N3Al8FfhAH+23X0eCbY/T3uPuvsz8Y4CI2INtTzb6Ov56DXTsehzuBIeVxq85wM8z8zKKKXlPoZ+HegCPA9Mj4vDy/QK2nT69LycB/yMzvwmcDBAR/W0fii8ET0YEcGxEHBgR7cDpwGXAm8oeLsBngf/Z5Lb+GTg1IiZFxDTgXez42FUTDIfx6ztAe0SsBn4MPEEx1ltRdsk/CPxjRDxM0ev43Q62fxFwX7n944Cn+tt+6XFgr4j48iD+Bo1PP6MYuvwX4BcUjwf+MPC1iPgX4A0Uw5Y7lJnLgXuBR4DlFNP87+jYVROceE+UZ3BfABZn5saI+ASwf2Y29T+o1CoR8SZgVmbeWP6w4kHgww3XzzRE9hxEZnZTXAD8YUQ8ChwP/HVrq5KaksAHIuInFD3krxoMw8OegySpwp6DJKnCcJAkVRgOkqQKw0HjTkR8JyL2GYH9nBkRH617P1IrGA4aj04aof0cC/zeCO1LGlH+WknjSkRcDyykmEvnUuDPgUkUM8femJmfLWeg/VtgI8U0DXMoJhU8A1hPcVPVezLz4IiYRDEJ3AkUd5g/QjGJ4NuA6yhuuPrrzLxqgJqeAm4o1zkQ+MeyjnaKu4N/n2ICujbgzMy8PyJuAH5LMW/VyyhmGu0C/giYWbZb1V99mfmfEfHnFBMzbqaYSuIjmbl6CP9ZtQuy56BxJTP/rHz5Voq7bv+0nKn294FPNww3vY5iCvPXA/MoAmUOcDTFF3WvCymm/jg6M4+guAP3C5l5B8UX9mUDBUODKZl5HPBm4PyIOIRi1tr9gDdl5mEUE9Bd2LDOG8q/43iKO4Y3ZOabKYKtt12f9ZVTmVwOvLOcOfcfKHo6UlOc60bjVQ/FWfa7ImIB8BqKM/M9y8+fycyny9d/ANyamf8BEBFXUZzlQzFXz17ASeWMoZOA54ZQzzcBMvMXEfEcsHdmPhgRi4CPRMQrKUJqfcM6d2bmFuDfI2IjL85O+q+8OMNon/Vl5gsRcSvwQEQsp5gG+6Yh1K1dlD0HjVd7UgyxvIHiztlPUTynondmzg0Nbbey7YydLzS83g04LzOPzMwjgbkUD5YZrMb5fnqAtoj4Q4r5gKAIj6u3q+P57bax/XM2BqwvMz9IEZA/p+hh3DyEurWLMhw0Hr1AMVwzDViUmXdSnJXvTt8z0y6nmNmz97kTZ/DizJ7/BJxbzvrZDlwDXFJ+tpXiyWVDdRJF7+DvgR9RPJxpoJlt+9JnfRGxT0Q8Q/GgnMuBRRTDZlJTDAeNR7dSjN//FHgiIh6nOINeDRy6fePMXEXxpfpgRPyI4uFEvy0//kuKGWcfKddv48UZQ1cA55QPPBqKq4F55UykP6YYLjqk/JJvVp/1ZeYvKZ7at7KcafcLwFlDrFO7IH+tpF1eRMwG3pyZV5TvPwG8MTPf19rKpNbxgrQE/wf4i4g4m2I46d+As5tdOSJOo7im0ZevZObf9POZNGrZc5AkVXjNQZJUYThIkioMB0lSheEgSaowHCRJFYaDJKni/wNHbTLRLH36BAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(df['target_names'],label='count')\n",
    "B,M = df['target_names'].value_counts()\n",
    "print('malignant',M)\n",
    "print('benign',B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1.drop(['target'],axis=1)\n",
    "y = df1.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.23,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROHIT\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=30, kernel_initializer=\"uniform\", activation=\"relu\", units=16)`\n",
      "  \n",
      "C:\\Users\\ROHIT\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"uniform\", activation=\"relu\", units=16)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\ROHIT\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"uniform\", activation=\"sigmoid\", units=1)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "clf = Sequential()\n",
    "clf.add(Dense( input_dim=30, output_dim=16, kernel_initializer=\"uniform\",activation='relu'))\n",
    "clf.add(Dense( output_dim=16, kernel_initializer=\"uniform\",activation='relu'))\n",
    "clf.add(Dense( output_dim=1, kernel_initializer=\"uniform\",activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.compile(optimizer='Adam', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROHIT\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "438/438 [==============================] - 2s 5ms/step - loss: 0.6927 - accuracy: 0.6507\n",
      "Epoch 2/150\n",
      "438/438 [==============================] - 0s 82us/step - loss: 0.6913 - accuracy: 0.6689\n",
      "Epoch 3/150\n",
      "438/438 [==============================] - 0s 83us/step - loss: 0.6892 - accuracy: 0.7420\n",
      "Epoch 4/150\n",
      "438/438 [==============================] - 0s 69us/step - loss: 0.6860 - accuracy: 0.8219\n",
      "Epoch 5/150\n",
      "438/438 [==============================] - 0s 76us/step - loss: 0.6810 - accuracy: 0.9087\n",
      "Epoch 6/150\n",
      "438/438 [==============================] - 0s 79us/step - loss: 0.6735 - accuracy: 0.9224\n",
      "Epoch 7/150\n",
      "438/438 [==============================] - 0s 78us/step - loss: 0.6624 - accuracy: 0.9269\n",
      "Epoch 8/150\n",
      "438/438 [==============================] - 0s 61us/step - loss: 0.6471 - accuracy: 0.9315\n",
      "Epoch 9/150\n",
      "438/438 [==============================] - 0s 107us/step - loss: 0.6271 - accuracy: 0.9361\n",
      "Epoch 10/150\n",
      "438/438 [==============================] - 0s 62us/step - loss: 0.6003 - accuracy: 0.9361\n",
      "Epoch 11/150\n",
      "438/438 [==============================] - 0s 88us/step - loss: 0.5680 - accuracy: 0.9406\n",
      "Epoch 12/150\n",
      "438/438 [==============================] - 0s 74us/step - loss: 0.5290 - accuracy: 0.9429\n",
      "Epoch 13/150\n",
      "438/438 [==============================] - 0s 99us/step - loss: 0.4862 - accuracy: 0.9429\n",
      "Epoch 14/150\n",
      "438/438 [==============================] - 0s 112us/step - loss: 0.4399 - accuracy: 0.9406\n",
      "Epoch 15/150\n",
      "438/438 [==============================] - 0s 67us/step - loss: 0.3936 - accuracy: 0.9406\n",
      "Epoch 16/150\n",
      "438/438 [==============================] - 0s 78us/step - loss: 0.3492 - accuracy: 0.9498\n",
      "Epoch 17/150\n",
      "438/438 [==============================] - 0s 64us/step - loss: 0.3078 - accuracy: 0.9498\n",
      "Epoch 18/150\n",
      "438/438 [==============================] - 0s 83us/step - loss: 0.2724 - accuracy: 0.9543\n",
      "Epoch 19/150\n",
      "438/438 [==============================] - 0s 71us/step - loss: 0.2407 - accuracy: 0.9589\n",
      "Epoch 20/150\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.2154 - accuracy: 0.96 - 0s 83us/step - loss: 0.2147 - accuracy: 0.9612\n",
      "Epoch 21/150\n",
      "438/438 [==============================] - 0s 524us/step - loss: 0.1932 - accuracy: 0.9635\n",
      "Epoch 22/150\n",
      "438/438 [==============================] - 0s 86us/step - loss: 0.1758 - accuracy: 0.9635\n",
      "Epoch 23/150\n",
      "438/438 [==============================] - 0s 90us/step - loss: 0.1608 - accuracy: 0.9658\n",
      "Epoch 24/150\n",
      "438/438 [==============================] - 0s 98us/step - loss: 0.1489 - accuracy: 0.9680\n",
      "Epoch 25/150\n",
      "438/438 [==============================] - 0s 88us/step - loss: 0.1385 - accuracy: 0.9680\n",
      "Epoch 26/150\n",
      "438/438 [==============================] - 0s 135us/step - loss: 0.1295 - accuracy: 0.9703\n",
      "Epoch 27/150\n",
      "438/438 [==============================] - 0s 177us/step - loss: 0.1221 - accuracy: 0.9726\n",
      "Epoch 28/150\n",
      "438/438 [==============================] - 0s 244us/step - loss: 0.1159 - accuracy: 0.9726\n",
      "Epoch 29/150\n",
      "438/438 [==============================] - 0s 91us/step - loss: 0.1103 - accuracy: 0.9726\n",
      "Epoch 30/150\n",
      "438/438 [==============================] - 0s 86us/step - loss: 0.1056 - accuracy: 0.9726\n",
      "Epoch 31/150\n",
      "438/438 [==============================] - 0s 79us/step - loss: 0.1014 - accuracy: 0.9749\n",
      "Epoch 32/150\n",
      "438/438 [==============================] - 0s 78us/step - loss: 0.0974 - accuracy: 0.9772\n",
      "Epoch 33/150\n",
      "438/438 [==============================] - 0s 71us/step - loss: 0.0941 - accuracy: 0.9772\n",
      "Epoch 34/150\n",
      "438/438 [==============================] - 0s 107us/step - loss: 0.0910 - accuracy: 0.9772\n",
      "Epoch 35/150\n",
      "438/438 [==============================] - 0s 94us/step - loss: 0.0882 - accuracy: 0.9795\n",
      "Epoch 36/150\n",
      "438/438 [==============================] - 0s 74us/step - loss: 0.0858 - accuracy: 0.9840\n",
      "Epoch 37/150\n",
      "438/438 [==============================] - 0s 107us/step - loss: 0.0836 - accuracy: 0.9840\n",
      "Epoch 38/150\n",
      "438/438 [==============================] - 0s 61us/step - loss: 0.0816 - accuracy: 0.9840\n",
      "Epoch 39/150\n",
      "438/438 [==============================] - 0s 82us/step - loss: 0.0797 - accuracy: 0.9840\n",
      "Epoch 40/150\n",
      "438/438 [==============================] - 0s 69us/step - loss: 0.0781 - accuracy: 0.9840\n",
      "Epoch 41/150\n",
      "438/438 [==============================] - 0s 79us/step - loss: 0.0763 - accuracy: 0.9840\n",
      "Epoch 42/150\n",
      "438/438 [==============================] - 0s 80us/step - loss: 0.0749 - accuracy: 0.9863\n",
      "Epoch 43/150\n",
      "438/438 [==============================] - 0s 168us/step - loss: 0.0734 - accuracy: 0.9863\n",
      "Epoch 44/150\n",
      "438/438 [==============================] - 0s 190us/step - loss: 0.0721 - accuracy: 0.9863\n",
      "Epoch 45/150\n",
      "438/438 [==============================] - 0s 478us/step - loss: 0.0709 - accuracy: 0.9840\n",
      "Epoch 46/150\n",
      "438/438 [==============================] - 0s 97us/step - loss: 0.0700 - accuracy: 0.9840\n",
      "Epoch 47/150\n",
      "438/438 [==============================] - 0s 105us/step - loss: 0.0687 - accuracy: 0.9840\n",
      "Epoch 48/150\n",
      "438/438 [==============================] - 0s 114us/step - loss: 0.0678 - accuracy: 0.9840\n",
      "Epoch 49/150\n",
      "438/438 [==============================] - 0s 73us/step - loss: 0.0668 - accuracy: 0.9840\n",
      "Epoch 50/150\n",
      "438/438 [==============================] - 0s 103us/step - loss: 0.0660 - accuracy: 0.9840\n",
      "Epoch 51/150\n",
      "438/438 [==============================] - 0s 84us/step - loss: 0.0653 - accuracy: 0.9840\n",
      "Epoch 52/150\n",
      "438/438 [==============================] - 0s 84us/step - loss: 0.0644 - accuracy: 0.9840\n",
      "Epoch 53/150\n",
      "438/438 [==============================] - 0s 86us/step - loss: 0.0636 - accuracy: 0.9840\n",
      "Epoch 54/150\n",
      "438/438 [==============================] - 0s 87us/step - loss: 0.0628 - accuracy: 0.9840\n",
      "Epoch 55/150\n",
      "438/438 [==============================] - 0s 88us/step - loss: 0.0622 - accuracy: 0.9840\n",
      "Epoch 56/150\n",
      "438/438 [==============================] - 0s 72us/step - loss: 0.0615 - accuracy: 0.9840\n",
      "Epoch 57/150\n",
      "438/438 [==============================] - 0s 59us/step - loss: 0.0609 - accuracy: 0.9840\n",
      "Epoch 58/150\n",
      "438/438 [==============================] - 0s 61us/step - loss: 0.0603 - accuracy: 0.9840\n",
      "Epoch 59/150\n",
      "438/438 [==============================] - 0s 72us/step - loss: 0.0597 - accuracy: 0.9840\n",
      "Epoch 60/150\n",
      "438/438 [==============================] - 0s 58us/step - loss: 0.0591 - accuracy: 0.9840\n",
      "Epoch 61/150\n",
      "438/438 [==============================] - 0s 90us/step - loss: 0.0585 - accuracy: 0.9840\n",
      "Epoch 62/150\n",
      "438/438 [==============================] - 0s 103us/step - loss: 0.0579 - accuracy: 0.9840\n",
      "Epoch 63/150\n",
      "438/438 [==============================] - 0s 98us/step - loss: 0.0574 - accuracy: 0.9840\n",
      "Epoch 64/150\n",
      "438/438 [==============================] - 0s 86us/step - loss: 0.0568 - accuracy: 0.9840\n",
      "Epoch 65/150\n",
      "438/438 [==============================] - 0s 177us/step - loss: 0.0563 - accuracy: 0.9840\n",
      "Epoch 66/150\n",
      "438/438 [==============================] - 0s 127us/step - loss: 0.0557 - accuracy: 0.9840\n",
      "Epoch 67/150\n",
      "438/438 [==============================] - 0s 65us/step - loss: 0.0553 - accuracy: 0.9840\n",
      "Epoch 68/150\n",
      "438/438 [==============================] - 0s 78us/step - loss: 0.0547 - accuracy: 0.9840\n",
      "Epoch 69/150\n",
      "438/438 [==============================] - 0s 67us/step - loss: 0.0542 - accuracy: 0.9840\n",
      "Epoch 70/150\n",
      "438/438 [==============================] - 0s 83us/step - loss: 0.0538 - accuracy: 0.9863\n",
      "Epoch 71/150\n",
      "438/438 [==============================] - 0s 118us/step - loss: 0.0533 - accuracy: 0.9863\n",
      "Epoch 72/150\n",
      "438/438 [==============================] - 0s 53us/step - loss: 0.0528 - accuracy: 0.9863\n",
      "Epoch 73/150\n",
      "438/438 [==============================] - 0s 63us/step - loss: 0.0523 - accuracy: 0.9863\n",
      "Epoch 74/150\n",
      "438/438 [==============================] - 0s 73us/step - loss: 0.0519 - accuracy: 0.9863\n",
      "Epoch 75/150\n",
      "438/438 [==============================] - 0s 73us/step - loss: 0.0514 - accuracy: 0.9863\n",
      "Epoch 76/150\n",
      "438/438 [==============================] - 0s 127us/step - loss: 0.0511 - accuracy: 0.9863\n",
      "Epoch 77/150\n",
      "438/438 [==============================] - 0s 115us/step - loss: 0.0506 - accuracy: 0.9863\n",
      "Epoch 78/150\n",
      "438/438 [==============================] - 0s 110us/step - loss: 0.0502 - accuracy: 0.9863\n",
      "Epoch 79/150\n",
      "438/438 [==============================] - 0s 105us/step - loss: 0.0498 - accuracy: 0.9863\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 0s 91us/step - loss: 0.0493 - accuracy: 0.9863\n",
      "Epoch 81/150\n",
      "438/438 [==============================] - 0s 113us/step - loss: 0.0490 - accuracy: 0.9863\n",
      "Epoch 82/150\n",
      "438/438 [==============================] - 0s 74us/step - loss: 0.0485 - accuracy: 0.9863\n",
      "Epoch 83/150\n",
      "438/438 [==============================] - 0s 69us/step - loss: 0.0481 - accuracy: 0.9863\n",
      "Epoch 84/150\n",
      "438/438 [==============================] - 0s 59us/step - loss: 0.0477 - accuracy: 0.9863\n",
      "Epoch 85/150\n",
      "438/438 [==============================] - 0s 59us/step - loss: 0.0473 - accuracy: 0.9863\n",
      "Epoch 86/150\n",
      "438/438 [==============================] - 0s 56us/step - loss: 0.0469 - accuracy: 0.9863\n",
      "Epoch 87/150\n",
      "438/438 [==============================] - 0s 48us/step - loss: 0.0465 - accuracy: 0.9886\n",
      "Epoch 88/150\n",
      "438/438 [==============================] - 0s 75us/step - loss: 0.0462 - accuracy: 0.9909\n",
      "Epoch 89/150\n",
      "438/438 [==============================] - 0s 83us/step - loss: 0.0458 - accuracy: 0.9886\n",
      "Epoch 90/150\n",
      "438/438 [==============================] - 0s 65us/step - loss: 0.0453 - accuracy: 0.9909\n",
      "Epoch 91/150\n",
      "438/438 [==============================] - 0s 61us/step - loss: 0.0448 - accuracy: 0.9909\n",
      "Epoch 92/150\n",
      "438/438 [==============================] - 0s 81us/step - loss: 0.0445 - accuracy: 0.9909\n",
      "Epoch 93/150\n",
      "438/438 [==============================] - 0s 56us/step - loss: 0.0441 - accuracy: 0.9909\n",
      "Epoch 94/150\n",
      "438/438 [==============================] - 0s 118us/step - loss: 0.0437 - accuracy: 0.9909\n",
      "Epoch 95/150\n",
      "438/438 [==============================] - 0s 96us/step - loss: 0.0434 - accuracy: 0.9909\n",
      "Epoch 96/150\n",
      "438/438 [==============================] - 0s 74us/step - loss: 0.0429 - accuracy: 0.9909\n",
      "Epoch 97/150\n",
      "438/438 [==============================] - 0s 84us/step - loss: 0.0426 - accuracy: 0.9909\n",
      "Epoch 98/150\n",
      "438/438 [==============================] - 0s 82us/step - loss: 0.0422 - accuracy: 0.9909\n",
      "Epoch 99/150\n",
      "438/438 [==============================] - 0s 106us/step - loss: 0.0418 - accuracy: 0.9909\n",
      "Epoch 100/150\n",
      "438/438 [==============================] - 0s 67us/step - loss: 0.0414 - accuracy: 0.9909\n",
      "Epoch 101/150\n",
      "438/438 [==============================] - 0s 61us/step - loss: 0.0409 - accuracy: 0.9909\n",
      "Epoch 102/150\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 1.00 - 0s 57us/step - loss: 0.0405 - accuracy: 0.9909\n",
      "Epoch 103/150\n",
      "438/438 [==============================] - 0s 83us/step - loss: 0.0403 - accuracy: 0.9909\n",
      "Epoch 104/150\n",
      "438/438 [==============================] - 0s 72us/step - loss: 0.0398 - accuracy: 0.9909\n",
      "Epoch 105/150\n",
      "438/438 [==============================] - 0s 75us/step - loss: 0.0393 - accuracy: 0.9909\n",
      "Epoch 106/150\n",
      "438/438 [==============================] - 0s 46us/step - loss: 0.0389 - accuracy: 0.9909\n",
      "Epoch 107/150\n",
      "438/438 [==============================] - 0s 97us/step - loss: 0.0384 - accuracy: 0.9909\n",
      "Epoch 108/150\n",
      "438/438 [==============================] - 0s 120us/step - loss: 0.0380 - accuracy: 0.9932\n",
      "Epoch 109/150\n",
      "438/438 [==============================] - 0s 94us/step - loss: 0.0377 - accuracy: 0.9932\n",
      "Epoch 110/150\n",
      "438/438 [==============================] - 0s 76us/step - loss: 0.0372 - accuracy: 0.9932\n",
      "Epoch 111/150\n",
      "438/438 [==============================] - 0s 89us/step - loss: 0.0369 - accuracy: 0.9932\n",
      "Epoch 112/150\n",
      "438/438 [==============================] - 0s 105us/step - loss: 0.0365 - accuracy: 0.9932\n",
      "Epoch 113/150\n",
      "438/438 [==============================] - 0s 221us/step - loss: 0.0359 - accuracy: 0.9932\n",
      "Epoch 114/150\n",
      "438/438 [==============================] - 0s 112us/step - loss: 0.0356 - accuracy: 0.9932\n",
      "Epoch 115/150\n",
      "438/438 [==============================] - 0s 108us/step - loss: 0.0351 - accuracy: 0.9932\n",
      "Epoch 116/150\n",
      "438/438 [==============================] - 0s 103us/step - loss: 0.0348 - accuracy: 0.9932\n",
      "Epoch 117/150\n",
      "438/438 [==============================] - 0s 96us/step - loss: 0.0344 - accuracy: 0.9932\n",
      "Epoch 118/150\n",
      "438/438 [==============================] - 0s 235us/step - loss: 0.0340 - accuracy: 0.99320s - loss: 0.0292 - accuracy: 0.99\n",
      "Epoch 119/150\n",
      "438/438 [==============================] - 0s 185us/step - loss: 0.0336 - accuracy: 0.9932\n",
      "Epoch 120/150\n",
      "438/438 [==============================] - 0s 103us/step - loss: 0.0332 - accuracy: 0.9932\n",
      "Epoch 121/150\n",
      "438/438 [==============================] - 0s 102us/step - loss: 0.0328 - accuracy: 0.9932\n",
      "Epoch 122/150\n",
      "438/438 [==============================] - 0s 92us/step - loss: 0.0324 - accuracy: 0.9932\n",
      "Epoch 123/150\n",
      "438/438 [==============================] - 0s 98us/step - loss: 0.0320 - accuracy: 0.9932\n",
      "Epoch 124/150\n",
      "438/438 [==============================] - 0s 123us/step - loss: 0.0316 - accuracy: 0.9932\n",
      "Epoch 125/150\n",
      "438/438 [==============================] - 0s 104us/step - loss: 0.0312 - accuracy: 0.9932\n",
      "Epoch 126/150\n",
      "438/438 [==============================] - 0s 185us/step - loss: 0.0308 - accuracy: 0.9932\n",
      "Epoch 127/150\n",
      "438/438 [==============================] - 0s 303us/step - loss: 0.0304 - accuracy: 0.9932\n",
      "Epoch 128/150\n",
      "438/438 [==============================] - 0s 105us/step - loss: 0.0300 - accuracy: 0.9932\n",
      "Epoch 129/150\n",
      "438/438 [==============================] - 0s 112us/step - loss: 0.0295 - accuracy: 0.9932\n",
      "Epoch 130/150\n",
      "438/438 [==============================] - 0s 81us/step - loss: 0.0292 - accuracy: 0.9932\n",
      "Epoch 131/150\n",
      "438/438 [==============================] - 0s 74us/step - loss: 0.0288 - accuracy: 0.9932\n",
      "Epoch 132/150\n",
      "438/438 [==============================] - 0s 122us/step - loss: 0.0284 - accuracy: 0.9932\n",
      "Epoch 133/150\n",
      "438/438 [==============================] - 0s 71us/step - loss: 0.0280 - accuracy: 0.9932\n",
      "Epoch 134/150\n",
      "438/438 [==============================] - 0s 54us/step - loss: 0.0276 - accuracy: 0.9932\n",
      "Epoch 135/150\n",
      "438/438 [==============================] - 0s 127us/step - loss: 0.0272 - accuracy: 0.9932\n",
      "Epoch 136/150\n",
      "438/438 [==============================] - 0s 83us/step - loss: 0.0269 - accuracy: 0.9932\n",
      "Epoch 137/150\n",
      "438/438 [==============================] - 0s 88us/step - loss: 0.0266 - accuracy: 0.9932\n",
      "Epoch 138/150\n",
      "438/438 [==============================] - 0s 84us/step - loss: 0.0262 - accuracy: 0.9932\n",
      "Epoch 139/150\n",
      "438/438 [==============================] - 0s 97us/step - loss: 0.0259 - accuracy: 0.9932\n",
      "Epoch 140/150\n",
      "438/438 [==============================] - 0s 91us/step - loss: 0.0256 - accuracy: 0.9932\n",
      "Epoch 141/150\n",
      "438/438 [==============================] - 0s 90us/step - loss: 0.0252 - accuracy: 0.9932\n",
      "Epoch 142/150\n",
      "438/438 [==============================] - 0s 79us/step - loss: 0.0250 - accuracy: 0.9932\n",
      "Epoch 143/150\n",
      "438/438 [==============================] - 0s 97us/step - loss: 0.0247 - accuracy: 0.9932\n",
      "Epoch 144/150\n",
      "438/438 [==============================] - 0s 72us/step - loss: 0.0243 - accuracy: 0.9932\n",
      "Epoch 145/150\n",
      "438/438 [==============================] - 0s 295us/step - loss: 0.0241 - accuracy: 0.9932\n",
      "Epoch 146/150\n",
      "438/438 [==============================] - 0s 79us/step - loss: 0.0238 - accuracy: 0.9932\n",
      "Epoch 147/150\n",
      "438/438 [==============================] - 0s 79us/step - loss: 0.0234 - accuracy: 0.9932\n",
      "Epoch 148/150\n",
      "438/438 [==============================] - 0s 92us/step - loss: 0.0231 - accuracy: 0.9932\n",
      "Epoch 149/150\n",
      "438/438 [==============================] - 0s 112us/step - loss: 0.0228 - accuracy: 0.9932\n",
      "Epoch 150/150\n",
      "438/438 [==============================] - 0s 394us/step - loss: 0.0224 - accuracy: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23414750c08>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train,y_train,batch_size=100,nb_epoch=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prd = clf.predict(x_test)\n",
    "y_prd = (y_prd > 0.5)\n",
    "y_prd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48,  2],\n",
       "       [ 0, 81]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23415dd39c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>5.1</th>\n",
       "      <th>3.5</th>\n",
       "      <th>1.4</th>\n",
       "      <th>0.2</th>\n",
       "      <th>Iris-setosa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>148</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  5.1  3.5  1.4  0.2     Iris-setosa\n",
       "0             0  4.9  3.0  1.4  0.2     Iris-setosa\n",
       "1             1  4.7  3.2  1.3  0.2     Iris-setosa\n",
       "2             2  4.6  3.1  1.5  0.2     Iris-setosa\n",
       "3             3  5.0  3.6  1.4  0.2     Iris-setosa\n",
       "4             4  5.4  3.9  1.7  0.4     Iris-setosa\n",
       "..          ...  ...  ...  ...  ...             ...\n",
       "144         144  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "145         145  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "146         146  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "147         147  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "148         148  5.9  3.0  5.1  1.8  Iris-virginica\n",
       "\n",
       "[149 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df2.drop(['Iris-setosa'],axis=1)\n",
    "y1 = df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5.1</th>\n",
       "      <th>3.5</th>\n",
       "      <th>1.4</th>\n",
       "      <th>0.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     5.1  3.5  1.4  0.2\n",
       "0    4.9  3.0  1.4  0.2\n",
       "1    4.7  3.2  1.3  0.2\n",
       "2    4.6  3.1  1.5  0.2\n",
       "3    5.0  3.6  1.4  0.2\n",
       "4    5.4  3.9  1.7  0.4\n",
       "..   ...  ...  ...  ...\n",
       "144  6.7  3.0  5.2  2.3\n",
       "145  6.3  2.5  5.0  1.9\n",
       "146  6.5  3.0  5.2  2.0\n",
       "147  6.2  3.4  5.4  2.3\n",
       "148  5.9  3.0  5.1  1.8\n",
       "\n",
       "[149 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "y2 = lb.fit_transform(y1)\n",
    "y1 = pd.get_dummies(y2).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train,x1_test,y1_train,y1_test = train_test_split(x1,y1,test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4,input_shape=(4,),activation='relu'))\n",
    "model.add(Dense(3,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROHIT\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 1.4220 - accuracy: 0.3507\n",
      "Epoch 2/100\n",
      "134/134 [==============================] - 0s 355us/step - loss: 1.3222 - accuracy: 0.3507\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 0s 381us/step - loss: 1.2469 - accuracy: 0.3507\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 0s 340us/step - loss: 1.1945 - accuracy: 0.3507\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 0s 358us/step - loss: 1.1569 - accuracy: 0.3433\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 0s 340us/step - loss: 1.1171 - accuracy: 0.3433\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 0s 351us/step - loss: 1.0853 - accuracy: 0.3284\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.9528 - accuracy: 0.50 - 0s 411us/step - loss: 1.0525 - accuracy: 0.3358\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 0s 402us/step - loss: 1.0218 - accuracy: 0.3507\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 0s 358us/step - loss: 0.9937 - accuracy: 0.3507\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.9552 - accuracy: 0.40 - 0s 347us/step - loss: 0.9636 - accuracy: 0.4328\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 0s 676us/step - loss: 0.9370 - accuracy: 0.5821\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 0s 754us/step - loss: 0.9114 - accuracy: 0.6418\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 0s 616us/step - loss: 0.8873 - accuracy: 0.6716\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 0s 776us/step - loss: 0.8645 - accuracy: 0.6866\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 0s 399us/step - loss: 0.8420 - accuracy: 0.6940\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 0s 403us/step - loss: 0.8211 - accuracy: 0.7164\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 0s 396us/step - loss: 0.8015 - accuracy: 0.7164\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 0s 537us/step - loss: 0.7815 - accuracy: 0.7164\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 0s 485us/step - loss: 0.7635 - accuracy: 0.7164\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 0s 515us/step - loss: 0.7451 - accuracy: 0.7015\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 0s 388us/step - loss: 0.7290 - accuracy: 0.7239\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 0s 384us/step - loss: 0.7125 - accuracy: 0.7313\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 0s 403us/step - loss: 0.6966 - accuracy: 0.7388\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 0s 388us/step - loss: 0.6824 - accuracy: 0.7164\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 0s 608us/step - loss: 0.6679 - accuracy: 0.7164\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 0s 496us/step - loss: 0.6546 - accuracy: 0.7388\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 0s 455us/step - loss: 0.6421 - accuracy: 0.7313\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 0s 377us/step - loss: 0.6293 - accuracy: 0.7463\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 0s 306us/step - loss: 0.6180 - accuracy: 0.7388\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 0s 545us/step - loss: 0.6064 - accuracy: 0.7761\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 0s 358us/step - loss: 0.5952 - accuracy: 0.8134\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 0s 317us/step - loss: 0.5845 - accuracy: 0.8209\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 0s 355us/step - loss: 0.5748 - accuracy: 0.8209\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 0s 366us/step - loss: 0.5653 - accuracy: 0.8134\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 0s 366us/step - loss: 0.5572 - accuracy: 0.8582\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 0s 370us/step - loss: 0.5477 - accuracy: 0.8881\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 0s 388us/step - loss: 0.5386 - accuracy: 0.8507\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 0s 370us/step - loss: 0.5303 - accuracy: 0.8582\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 0s 366us/step - loss: 0.5221 - accuracy: 0.8806\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 0s 631us/step - loss: 0.5146 - accuracy: 0.8582\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 0s 784us/step - loss: 0.5073 - accuracy: 0.9030\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 0s 410us/step - loss: 0.5006 - accuracy: 0.9328\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 0s 694us/step - loss: 0.4935 - accuracy: 0.9030\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 0s 769us/step - loss: 0.4868 - accuracy: 0.9179\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 0s 698us/step - loss: 0.4805 - accuracy: 0.9104\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 0s 407us/step - loss: 0.4744 - accuracy: 0.8955\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4389 - accuracy: 1.00 - 0s 411us/step - loss: 0.4685 - accuracy: 0.8955\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 0s 519us/step - loss: 0.4635 - accuracy: 0.8806\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 0s 384us/step - loss: 0.4561 - accuracy: 0.9179\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 0s 336us/step - loss: 0.4504 - accuracy: 0.9328\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 0s 373us/step - loss: 0.4454 - accuracy: 0.9328\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 0s 284us/step - loss: 0.4398 - accuracy: 0.9328\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 0s 396us/step - loss: 0.4348 - accuracy: 0.9328\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 0s 351us/step - loss: 0.4298 - accuracy: 0.9328\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 0s 343us/step - loss: 0.4246 - accuracy: 0.9403\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 0s 373us/step - loss: 0.4195 - accuracy: 0.9403\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 0s 403us/step - loss: 0.4149 - accuracy: 0.9328\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 0s 401us/step - loss: 0.4094 - accuracy: 0.9403\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 0s 399us/step - loss: 0.4049 - accuracy: 0.9552\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 0s 564us/step - loss: 0.4010 - accuracy: 0.9627\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 0s 504us/step - loss: 0.3967 - accuracy: 0.9478\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 0s 414us/step - loss: 0.3915 - accuracy: 0.9627\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 0s 519us/step - loss: 0.3872 - accuracy: 0.9552\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 0s 396us/step - loss: 0.3827 - accuracy: 0.9552\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 0s 340us/step - loss: 0.3784 - accuracy: 0.9627\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 0s 315us/step - loss: 0.3747 - accuracy: 0.9627\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 0s 355us/step - loss: 0.3703 - accuracy: 0.9552\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 0s 299us/step - loss: 0.3663 - accuracy: 0.9478\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 0s 276us/step - loss: 0.3623 - accuracy: 0.9552\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 0s 500us/step - loss: 0.3589 - accuracy: 0.9627\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 0s 795us/step - loss: 0.3561 - accuracy: 0.9627\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4768 - accuracy: 0.80 - 0s 299us/step - loss: 0.3505 - accuracy: 0.9627\n",
      "Epoch 74/100\n",
      "134/134 [==============================] - 0s 675us/step - loss: 0.3471 - accuracy: 0.9701\n",
      "Epoch 75/100\n",
      "134/134 [==============================] - 0s 515us/step - loss: 0.3428 - accuracy: 0.9701\n",
      "Epoch 76/100\n",
      "134/134 [==============================] - 0s 414us/step - loss: 0.3406 - accuracy: 0.9701\n",
      "Epoch 77/100\n",
      "134/134 [==============================] - 0s 347us/step - loss: 0.3356 - accuracy: 0.9776\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 347us/step - loss: 0.3331 - accuracy: 0.9627\n",
      "Epoch 79/100\n",
      "134/134 [==============================] - 0s 306us/step - loss: 0.3299 - accuracy: 0.9776\n",
      "Epoch 80/100\n",
      "134/134 [==============================] - 0s 306us/step - loss: 0.3253 - accuracy: 0.9627\n",
      "Epoch 81/100\n",
      "134/134 [==============================] - 0s 276us/step - loss: 0.3223 - accuracy: 0.9627\n",
      "Epoch 82/100\n",
      "134/134 [==============================] - 0s 291us/step - loss: 0.3182 - accuracy: 0.9627\n",
      "Epoch 83/100\n",
      "134/134 [==============================] - 0s 304us/step - loss: 0.3152 - accuracy: 0.9701\n",
      "Epoch 84/100\n",
      "134/134 [==============================] - 0s 421us/step - loss: 0.3115 - accuracy: 0.9776\n",
      "Epoch 85/100\n",
      "134/134 [==============================] - 0s 343us/step - loss: 0.3084 - accuracy: 0.9701\n",
      "Epoch 86/100\n",
      "134/134 [==============================] - 0s 258us/step - loss: 0.3051 - accuracy: 0.9627\n",
      "Epoch 87/100\n",
      "134/134 [==============================] - 0s 291us/step - loss: 0.3026 - accuracy: 0.9701\n",
      "Epoch 88/100\n",
      "134/134 [==============================] - 0s 254us/step - loss: 0.2986 - accuracy: 0.9776\n",
      "Epoch 89/100\n",
      "134/134 [==============================] - 0s 276us/step - loss: 0.2954 - accuracy: 0.9701\n",
      "Epoch 90/100\n",
      "134/134 [==============================] - 0s 276us/step - loss: 0.2930 - accuracy: 0.9627\n",
      "Epoch 91/100\n",
      "134/134 [==============================] - 0s 299us/step - loss: 0.2892 - accuracy: 0.9627\n",
      "Epoch 92/100\n",
      "134/134 [==============================] - 0s 254us/step - loss: 0.2867 - accuracy: 0.9701\n",
      "Epoch 93/100\n",
      "134/134 [==============================] - 0s 276us/step - loss: 0.2861 - accuracy: 0.9627\n",
      "Epoch 94/100\n",
      "134/134 [==============================] - 0s 276us/step - loss: 0.2809 - accuracy: 0.9701\n",
      "Epoch 95/100\n",
      "134/134 [==============================] - 0s 313us/step - loss: 0.2784 - accuracy: 0.9776\n",
      "Epoch 96/100\n",
      "134/134 [==============================] - 0s 314us/step - loss: 0.2747 - accuracy: 0.9776\n",
      "Epoch 97/100\n",
      "134/134 [==============================] - 0s 306us/step - loss: 0.2719 - accuracy: 0.9701\n",
      "Epoch 98/100\n",
      "134/134 [==============================] - 0s 299us/step - loss: 0.2693 - accuracy: 0.9627\n",
      "Epoch 99/100\n",
      "134/134 [==============================] - 0s 511us/step - loss: 0.2676 - accuracy: 0.9776\n",
      "Epoch 100/100\n",
      "134/134 [==============================] - 0s 787us/step - loss: 0.2638 - accuracy: 0.9701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23415ee9608>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x1_train,y1_train,batch_size=10,nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clssf():\n",
    "    clf = Sequential()\n",
    "    clf.add(Dense( input_dim=30, output_dim=16, kernel_initializer=\"uniform\",activation='relu'))\n",
    "    clf.add(Dense( output_dim=16, kernel_initializer=\"uniform\",activation='relu'))\n",
    "    clf.add(Dense( output_dim=1, kernel_initializer=\"uniform\",activation='sigmoid'))\n",
    "    clf.compile(optimizer='Adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return clf\n",
    "clf = KerasClassifier(build_fn=clssf,batch_size=100,epochs=100)\n",
    "accur = cross_val_score(estimator= clf, X= x_train,y=y_train,cv=10,n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9749471485614777"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = accur.mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.97727275, 0.97727275, 0.93181819, 0.95454544,\n",
       "       1.        , 1.        , 0.93181819, 1.        , 0.97674417])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025809052657714743"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accur.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROHIT\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=30, kernel_initializer=\"uniform\", activation=\"relu\", units=16)`\n",
      "  \n",
      "C:\\Users\\ROHIT\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=1.0)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\ROHIT\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"uniform\", activation=\"relu\", units=16)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\ROHIT\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=1.0)`\n",
      "  \"\"\"\n",
      "C:\\Users\\ROHIT\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"uniform\", activation=\"sigmoid\", units=1)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "clf = Sequential()\n",
    "clf.add(Dense( input_dim=30, output_dim=16, kernel_initializer=\"uniform\",activation='relu'))\n",
    "clf.add(Dropout(p=1.0))\n",
    "clf.add(Dense( output_dim=16, kernel_initializer=\"uniform\",activation='relu'))\n",
    "clf.add(Dropout(p=1.0))\n",
    "clf.add(Dense( output_dim=1, kernel_initializer=\"uniform\",activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.compile(optimizer='Adam', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROHIT\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "438/438 [==============================] - 2s 5ms/step - loss: 0.6928 - accuracy: 0.6301\n",
      "Epoch 2/150\n",
      "438/438 [==============================] - 0s 73us/step - loss: 0.6911 - accuracy: 0.6301\n",
      "Epoch 3/150\n",
      "438/438 [==============================] - 0s 73us/step - loss: 0.6888 - accuracy: 0.6301\n",
      "Epoch 4/150\n",
      "438/438 [==============================] - 0s 74us/step - loss: 0.6852 - accuracy: 0.6301\n",
      "Epoch 5/150\n",
      "438/438 [==============================] - 0s 116us/step - loss: 0.6793 - accuracy: 0.6393\n",
      "Epoch 6/150\n",
      "438/438 [==============================] - 0s 467us/step - loss: 0.6704 - accuracy: 0.7215\n",
      "Epoch 7/150\n",
      "438/438 [==============================] - 0s 119us/step - loss: 0.6580 - accuracy: 0.8402\n",
      "Epoch 8/150\n",
      "438/438 [==============================] - 0s 73us/step - loss: 0.6402 - accuracy: 0.9110\n",
      "Epoch 9/150\n",
      "438/438 [==============================] - 0s 80us/step - loss: 0.6167 - accuracy: 0.9338\n",
      "Epoch 10/150\n",
      "438/438 [==============================] - 0s 87us/step - loss: 0.5863 - accuracy: 0.9292\n",
      "Epoch 11/150\n",
      "438/438 [==============================] - 0s 70us/step - loss: 0.5501 - accuracy: 0.9315\n",
      "Epoch 12/150\n",
      "438/438 [==============================] - 0s 54us/step - loss: 0.5066 - accuracy: 0.9361\n",
      "Epoch 13/150\n",
      "438/438 [==============================] - 0s 73us/step - loss: 0.4609 - accuracy: 0.9384\n",
      "Epoch 14/150\n",
      "438/438 [==============================] - 0s 64us/step - loss: 0.4136 - accuracy: 0.9361\n",
      "Epoch 15/150\n",
      "438/438 [==============================] - 0s 78us/step - loss: 0.3673 - accuracy: 0.9384\n",
      "Epoch 16/150\n",
      "438/438 [==============================] - 0s 87us/step - loss: 0.3242 - accuracy: 0.9384\n",
      "Epoch 17/150\n",
      "438/438 [==============================] - 0s 68us/step - loss: 0.2864 - accuracy: 0.9429\n",
      "Epoch 18/150\n",
      "438/438 [==============================] - 0s 78us/step - loss: 0.2542 - accuracy: 0.9452\n",
      "Epoch 19/150\n",
      "438/438 [==============================] - 0s 87us/step - loss: 0.2271 - accuracy: 0.9475\n",
      "Epoch 20/150\n",
      "438/438 [==============================] - 0s 67us/step - loss: 0.2040 - accuracy: 0.9521\n",
      "Epoch 21/150\n",
      "438/438 [==============================] - 0s 102us/step - loss: 0.1853 - accuracy: 0.9589\n",
      "Epoch 22/150\n",
      "438/438 [==============================] - 0s 72us/step - loss: 0.1699 - accuracy: 0.9612\n",
      "Epoch 23/150\n",
      "438/438 [==============================] - 0s 82us/step - loss: 0.1575 - accuracy: 0.9635\n",
      "Epoch 24/150\n",
      "438/438 [==============================] - 0s 68us/step - loss: 0.1466 - accuracy: 0.9635\n",
      "Epoch 25/150\n",
      "438/438 [==============================] - 0s 74us/step - loss: 0.1378 - accuracy: 0.9635\n",
      "Epoch 26/150\n",
      "438/438 [==============================] - 0s 90us/step - loss: 0.1303 - accuracy: 0.9635\n",
      "Epoch 27/150\n",
      "438/438 [==============================] - 0s 65us/step - loss: 0.1237 - accuracy: 0.9658\n",
      "Epoch 28/150\n",
      "438/438 [==============================] - 0s 90us/step - loss: 0.1178 - accuracy: 0.9658\n",
      "Epoch 29/150\n",
      "438/438 [==============================] - 0s 97us/step - loss: 0.1130 - accuracy: 0.9703\n",
      "Epoch 30/150\n",
      "438/438 [==============================] - 0s 175us/step - loss: 0.1085 - accuracy: 0.9703\n",
      "Epoch 31/150\n",
      "438/438 [==============================] - 0s 124us/step - loss: 0.1044 - accuracy: 0.9726\n",
      "Epoch 32/150\n",
      "438/438 [==============================] - 0s 208us/step - loss: 0.1006 - accuracy: 0.9726\n",
      "Epoch 33/150\n",
      "438/438 [==============================] - 0s 228us/step - loss: 0.0975 - accuracy: 0.9726\n",
      "Epoch 34/150\n",
      "438/438 [==============================] - 0s 82us/step - loss: 0.0944 - accuracy: 0.9749\n",
      "Epoch 35/150\n",
      "438/438 [==============================] - 0s 84us/step - loss: 0.0916 - accuracy: 0.9795\n",
      "Epoch 36/150\n",
      "438/438 [==============================] - 0s 113us/step - loss: 0.0891 - accuracy: 0.9795\n",
      "Epoch 37/150\n",
      "438/438 [==============================] - 0s 99us/step - loss: 0.0868 - accuracy: 0.9795\n",
      "Epoch 38/150\n",
      "438/438 [==============================] - 0s 92us/step - loss: 0.0849 - accuracy: 0.9817\n",
      "Epoch 39/150\n",
      "438/438 [==============================] - 0s 102us/step - loss: 0.0828 - accuracy: 0.9817\n",
      "Epoch 40/150\n",
      "438/438 [==============================] - 0s 99us/step - loss: 0.0809 - accuracy: 0.9817\n",
      "Epoch 41/150\n",
      "438/438 [==============================] - 0s 76us/step - loss: 0.0793 - accuracy: 0.9817\n",
      "Epoch 42/150\n",
      "438/438 [==============================] - 0s 108us/step - loss: 0.0778 - accuracy: 0.9817\n",
      "Epoch 43/150\n",
      "438/438 [==============================] - 0s 123us/step - loss: 0.0762 - accuracy: 0.9817\n",
      "Epoch 44/150\n",
      "438/438 [==============================] - 0s 95us/step - loss: 0.0749 - accuracy: 0.9817\n",
      "Epoch 45/150\n",
      "438/438 [==============================] - 0s 94us/step - loss: 0.0736 - accuracy: 0.9817\n",
      "Epoch 46/150\n",
      "438/438 [==============================] - 0s 94us/step - loss: 0.0725 - accuracy: 0.9840\n",
      "Epoch 47/150\n",
      "438/438 [==============================] - 0s 98us/step - loss: 0.0713 - accuracy: 0.9840\n",
      "Epoch 48/150\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.98 - 0s 107us/step - loss: 0.0703 - accuracy: 0.9863\n",
      "Epoch 49/150\n",
      "438/438 [==============================] - 0s 81us/step - loss: 0.0693 - accuracy: 0.9863\n",
      "Epoch 50/150\n",
      "438/438 [==============================] - 0s 168us/step - loss: 0.0684 - accuracy: 0.9863\n",
      "Epoch 51/150\n",
      "438/438 [==============================] - 0s 257us/step - loss: 0.0675 - accuracy: 0.9863\n",
      "Epoch 52/150\n",
      "438/438 [==============================] - 0s 67us/step - loss: 0.0668 - accuracy: 0.9863\n",
      "Epoch 53/150\n",
      "438/438 [==============================] - 0s 210us/step - loss: 0.0659 - accuracy: 0.9863\n",
      "Epoch 54/150\n",
      "438/438 [==============================] - 0s 217us/step - loss: 0.0652 - accuracy: 0.9863\n",
      "Epoch 55/150\n",
      "438/438 [==============================] - 0s 82us/step - loss: 0.0645 - accuracy: 0.9863\n",
      "Epoch 56/150\n",
      "438/438 [==============================] - 0s 92us/step - loss: 0.0638 - accuracy: 0.9863\n",
      "Epoch 57/150\n",
      "438/438 [==============================] - 0s 73us/step - loss: 0.0632 - accuracy: 0.9863\n",
      "Epoch 58/150\n",
      "438/438 [==============================] - 0s 80us/step - loss: 0.0625 - accuracy: 0.9863\n",
      "Epoch 59/150\n",
      "438/438 [==============================] - 0s 50us/step - loss: 0.0618 - accuracy: 0.9840\n",
      "Epoch 60/150\n",
      "438/438 [==============================] - 0s 61us/step - loss: 0.0614 - accuracy: 0.9840\n",
      "Epoch 61/150\n",
      "438/438 [==============================] - 0s 91us/step - loss: 0.0607 - accuracy: 0.9840\n",
      "Epoch 62/150\n",
      "438/438 [==============================] - 0s 81us/step - loss: 0.0601 - accuracy: 0.9840\n",
      "Epoch 63/150\n",
      "438/438 [==============================] - 0s 80us/step - loss: 0.0596 - accuracy: 0.9840\n",
      "Epoch 64/150\n",
      "438/438 [==============================] - 0s 82us/step - loss: 0.0591 - accuracy: 0.9840\n",
      "Epoch 65/150\n",
      "438/438 [==============================] - 0s 95us/step - loss: 0.0585 - accuracy: 0.9840\n",
      "Epoch 66/150\n",
      "438/438 [==============================] - 0s 89us/step - loss: 0.0580 - accuracy: 0.9840\n",
      "Epoch 67/150\n",
      "438/438 [==============================] - 0s 87us/step - loss: 0.0575 - accuracy: 0.9840\n",
      "Epoch 68/150\n",
      "438/438 [==============================] - 0s 73us/step - loss: 0.0570 - accuracy: 0.9840\n",
      "Epoch 69/150\n",
      "438/438 [==============================] - 0s 63us/step - loss: 0.0565 - accuracy: 0.9840\n",
      "Epoch 70/150\n",
      "438/438 [==============================] - 0s 91us/step - loss: 0.0560 - accuracy: 0.9840\n",
      "Epoch 71/150\n",
      "438/438 [==============================] - 0s 62us/step - loss: 0.0556 - accuracy: 0.9840\n",
      "Epoch 72/150\n",
      "438/438 [==============================] - 0s 71us/step - loss: 0.0551 - accuracy: 0.9840\n",
      "Epoch 73/150\n",
      "438/438 [==============================] - 0s 71us/step - loss: 0.0546 - accuracy: 0.9840\n",
      "Epoch 74/150\n",
      "438/438 [==============================] - 0s 50us/step - loss: 0.0541 - accuracy: 0.9840\n",
      "Epoch 75/150\n",
      "438/438 [==============================] - 0s 74us/step - loss: 0.0537 - accuracy: 0.9863\n",
      "Epoch 76/150\n",
      "438/438 [==============================] - 0s 178us/step - loss: 0.0533 - accuracy: 0.9863\n",
      "Epoch 77/150\n",
      "438/438 [==============================] - 0s 123us/step - loss: 0.0528 - accuracy: 0.9863\n",
      "Epoch 78/150\n",
      "438/438 [==============================] - 0s 228us/step - loss: 0.0525 - accuracy: 0.9863\n",
      "Epoch 79/150\n",
      "438/438 [==============================] - 0s 170us/step - loss: 0.0520 - accuracy: 0.9863\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 0s 89us/step - loss: 0.0516 - accuracy: 0.9863\n",
      "Epoch 81/150\n",
      "438/438 [==============================] - 0s 80us/step - loss: 0.0511 - accuracy: 0.9863\n",
      "Epoch 82/150\n",
      "438/438 [==============================] - 0s 64us/step - loss: 0.0507 - accuracy: 0.9863\n",
      "Epoch 83/150\n",
      "438/438 [==============================] - 0s 54us/step - loss: 0.0503 - accuracy: 0.9863\n",
      "Epoch 84/150\n",
      "438/438 [==============================] - 0s 90us/step - loss: 0.0500 - accuracy: 0.9863\n",
      "Epoch 85/150\n",
      "438/438 [==============================] - 0s 53us/step - loss: 0.0494 - accuracy: 0.9863\n",
      "Epoch 86/150\n",
      "438/438 [==============================] - 0s 78us/step - loss: 0.0488 - accuracy: 0.9863\n",
      "Epoch 87/150\n",
      "438/438 [==============================] - 0s 65us/step - loss: 0.0483 - accuracy: 0.9863\n",
      "Epoch 88/150\n",
      "438/438 [==============================] - 0s 49us/step - loss: 0.0477 - accuracy: 0.9863\n",
      "Epoch 89/150\n",
      "438/438 [==============================] - 0s 61us/step - loss: 0.0472 - accuracy: 0.9863\n",
      "Epoch 90/150\n",
      "438/438 [==============================] - 0s 65us/step - loss: 0.0467 - accuracy: 0.9863\n",
      "Epoch 91/150\n",
      "438/438 [==============================] - 0s 56us/step - loss: 0.0462 - accuracy: 0.9863\n",
      "Epoch 92/150\n",
      "438/438 [==============================] - 0s 61us/step - loss: 0.0456 - accuracy: 0.9863\n",
      "Epoch 93/150\n",
      "438/438 [==============================] - 0s 89us/step - loss: 0.0451 - accuracy: 0.9863\n",
      "Epoch 94/150\n",
      "438/438 [==============================] - 0s 75us/step - loss: 0.0447 - accuracy: 0.9863\n",
      "Epoch 95/150\n",
      "438/438 [==============================] - 0s 47us/step - loss: 0.0440 - accuracy: 0.9863\n",
      "Epoch 96/150\n",
      "438/438 [==============================] - 0s 72us/step - loss: 0.0435 - accuracy: 0.9863\n",
      "Epoch 97/150\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.98 - 0s 55us/step - loss: 0.0429 - accuracy: 0.9863\n",
      "Epoch 98/150\n",
      "438/438 [==============================] - 0s 66us/step - loss: 0.0424 - accuracy: 0.9863\n",
      "Epoch 99/150\n",
      "438/438 [==============================] - 0s 55us/step - loss: 0.0418 - accuracy: 0.9863\n",
      "Epoch 100/150\n",
      "438/438 [==============================] - 0s 67us/step - loss: 0.0412 - accuracy: 0.9886\n",
      "Epoch 101/150\n",
      "438/438 [==============================] - 0s 69us/step - loss: 0.0406 - accuracy: 0.9886\n",
      "Epoch 102/150\n",
      "438/438 [==============================] - 0s 78us/step - loss: 0.0400 - accuracy: 0.9909\n",
      "Epoch 103/150\n",
      "438/438 [==============================] - 0s 61us/step - loss: 0.0394 - accuracy: 0.9909\n",
      "Epoch 104/150\n",
      "438/438 [==============================] - 0s 108us/step - loss: 0.0389 - accuracy: 0.9909\n",
      "Epoch 105/150\n",
      "438/438 [==============================] - 0s 132us/step - loss: 0.0384 - accuracy: 0.9909\n",
      "Epoch 106/150\n",
      "438/438 [==============================] - 0s 139us/step - loss: 0.0380 - accuracy: 0.9909\n",
      "Epoch 107/150\n",
      "438/438 [==============================] - 0s 316us/step - loss: 0.0374 - accuracy: 0.9909\n",
      "Epoch 108/150\n",
      "438/438 [==============================] - 0s 95us/step - loss: 0.0368 - accuracy: 0.9909\n",
      "Epoch 109/150\n",
      "438/438 [==============================] - 0s 94us/step - loss: 0.0363 - accuracy: 0.9909\n",
      "Epoch 110/150\n",
      "438/438 [==============================] - 0s 74us/step - loss: 0.0359 - accuracy: 0.9909\n",
      "Epoch 111/150\n",
      "438/438 [==============================] - 0s 83us/step - loss: 0.0354 - accuracy: 0.9909\n",
      "Epoch 112/150\n",
      "438/438 [==============================] - 0s 87us/step - loss: 0.0349 - accuracy: 0.9909\n",
      "Epoch 113/150\n",
      "438/438 [==============================] - 0s 83us/step - loss: 0.0344 - accuracy: 0.9909\n",
      "Epoch 114/150\n",
      "438/438 [==============================] - 0s 89us/step - loss: 0.0340 - accuracy: 0.9909\n",
      "Epoch 115/150\n",
      "438/438 [==============================] - 0s 80us/step - loss: 0.0336 - accuracy: 0.9909\n",
      "Epoch 116/150\n",
      "438/438 [==============================] - 0s 79us/step - loss: 0.0332 - accuracy: 0.9909\n",
      "Epoch 117/150\n",
      "438/438 [==============================] - 0s 67us/step - loss: 0.0328 - accuracy: 0.9932\n",
      "Epoch 118/150\n",
      "438/438 [==============================] - 0s 64us/step - loss: 0.0324 - accuracy: 0.9932\n",
      "Epoch 119/150\n",
      "438/438 [==============================] - 0s 62us/step - loss: 0.0318 - accuracy: 0.9932\n",
      "Epoch 120/150\n",
      "438/438 [==============================] - 0s 75us/step - loss: 0.0314 - accuracy: 0.9932\n",
      "Epoch 121/150\n",
      "438/438 [==============================] - 0s 65us/step - loss: 0.0312 - accuracy: 0.9932\n",
      "Epoch 122/150\n",
      "438/438 [==============================] - 0s 66us/step - loss: 0.0309 - accuracy: 0.9932\n",
      "Epoch 123/150\n",
      "438/438 [==============================] - 0s 62us/step - loss: 0.0305 - accuracy: 0.9932\n",
      "Epoch 124/150\n",
      "438/438 [==============================] - 0s 51us/step - loss: 0.0301 - accuracy: 0.9932\n",
      "Epoch 125/150\n",
      "438/438 [==============================] - 0s 63us/step - loss: 0.0296 - accuracy: 0.9932\n",
      "Epoch 126/150\n",
      "438/438 [==============================] - 0s 78us/step - loss: 0.0292 - accuracy: 0.9932\n",
      "Epoch 127/150\n",
      "438/438 [==============================] - 0s 49us/step - loss: 0.0288 - accuracy: 0.9932\n",
      "Epoch 128/150\n",
      "438/438 [==============================] - 0s 67us/step - loss: 0.0285 - accuracy: 0.9932\n",
      "Epoch 129/150\n",
      "438/438 [==============================] - 0s 94us/step - loss: 0.0281 - accuracy: 0.9932\n",
      "Epoch 130/150\n",
      "438/438 [==============================] - 0s 126us/step - loss: 0.0277 - accuracy: 0.9932\n",
      "Epoch 131/150\n",
      "438/438 [==============================] - 0s 352us/step - loss: 0.0274 - accuracy: 0.9932\n",
      "Epoch 132/150\n",
      "438/438 [==============================] - 0s 106us/step - loss: 0.0271 - accuracy: 0.9932\n",
      "Epoch 133/150\n",
      "438/438 [==============================] - 0s 63us/step - loss: 0.0268 - accuracy: 0.9932\n",
      "Epoch 134/150\n",
      "438/438 [==============================] - 0s 81us/step - loss: 0.0264 - accuracy: 0.9932\n",
      "Epoch 135/150\n",
      "438/438 [==============================] - 0s 83us/step - loss: 0.0261 - accuracy: 0.9932\n",
      "Epoch 136/150\n",
      "438/438 [==============================] - 0s 107us/step - loss: 0.0258 - accuracy: 0.9932\n",
      "Epoch 137/150\n",
      "438/438 [==============================] - 0s 119us/step - loss: 0.0254 - accuracy: 0.9932\n",
      "Epoch 138/150\n",
      "438/438 [==============================] - 0s 67us/step - loss: 0.0251 - accuracy: 0.9932\n",
      "Epoch 139/150\n",
      "438/438 [==============================] - 0s 72us/step - loss: 0.0248 - accuracy: 0.9932\n",
      "Epoch 140/150\n",
      "438/438 [==============================] - 0s 59us/step - loss: 0.0245 - accuracy: 0.9932\n",
      "Epoch 141/150\n",
      "438/438 [==============================] - 0s 67us/step - loss: 0.0241 - accuracy: 0.9932\n",
      "Epoch 142/150\n",
      "438/438 [==============================] - 0s 67us/step - loss: 0.0238 - accuracy: 0.9932\n",
      "Epoch 143/150\n",
      "438/438 [==============================] - 0s 75us/step - loss: 0.0236 - accuracy: 0.9932\n",
      "Epoch 144/150\n",
      "438/438 [==============================] - 0s 75us/step - loss: 0.0232 - accuracy: 0.9932\n",
      "Epoch 145/150\n",
      "438/438 [==============================] - 0s 78us/step - loss: 0.0229 - accuracy: 0.9932\n",
      "Epoch 146/150\n",
      "438/438 [==============================] - 0s 69us/step - loss: 0.0226 - accuracy: 0.9932\n",
      "Epoch 147/150\n",
      "438/438 [==============================] - 0s 89us/step - loss: 0.0222 - accuracy: 0.9932\n",
      "Epoch 148/150\n",
      "438/438 [==============================] - 0s 56us/step - loss: 0.0220 - accuracy: 0.9932\n",
      "Epoch 149/150\n",
      "438/438 [==============================] - 0s 63us/step - loss: 0.0216 - accuracy: 0.9932\n",
      "Epoch 150/150\n",
      "438/438 [==============================] - 0s 66us/step - loss: 0.0214 - accuracy: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x234161f3c08>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train,y_train,batch_size=100,nb_epoch=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prd1 = clf.predict(x_test)\n",
    "y_prd1 = (y_prd1 > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm1 = confusion_matrix(y_test,y_prd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49,  1],\n",
       "       [ 0, 81]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x234175d9a88>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm1, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def clssf(optimizer='adam'):\n",
    "    clf = Sequential()\n",
    "    clf.add(Dense( input_dim=30, output_dim=16, kernel_initializer=\"uniform\",activation='relu'))\n",
    "    clf.add(Dense( output_dim=16, kernel_initializer=\"uniform\",activation='relu'))\n",
    "    clf.add(Dense( output_dim=1, kernel_initializer=\"uniform\",activation='sigmoid'))\n",
    "    clf.compile(optimizer='Adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return clf\n",
    "clf = KerasClassifier(build_fn=clssf)\n",
    "par = {'batch_size':[100,150],'epochs':[100,200],'optimizer':['adam','rmsprop']}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grd = GridSearchCV(estimator=clf,param_grid=par,scoring='accuracy',cv=10)\n",
    "grd_srch = grd.fit(x_train,y_train)\n",
    "bst_prms = grd_srch.best_params_\n",
    "best_acc = grd_srch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bst_prms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-a95e3f95e224>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbst_prms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'bst_prms' is not defined"
     ]
    }
   ],
   "source": [
    "bst_prms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
